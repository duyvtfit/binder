{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#@title gradient descent\n\"\"\"\nprediction: manually\ngradient computation: manually\nloss computation: manually\nparameter updates: manually\n\"\"\"\n\nimport numpy as np\n\n\nX = np.array([1, 2, 3, 4], dtype=np.float32)\nY = np.array([2, 4, 6, 8], dtype=np.float32)\n\nw = 0.0\n\n# model prediction\ndef forward(x):\n    return w * x\n\n# loss = MSE\ndef loss(y, y_predicted):\n    return((y_predicted - y)**2).mean()\n\n# gradient\n# MSE = 1/N * (w*x - y)**2\ndef gradient(x, y, y_predicted):\n    return np.dot(2*x, y_predicted - y).mean()\n\nprint(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n\n# Training\nlearning_rate = 0.01\nn_iters = 20\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = forward(X)\n    \n    # loss\n    l = loss(Y, y_pred)\n    \n    # gradients\n    dw = gradient(X, Y, y_pred)\n    \n    # update weight\n    w -= learning_rate * dw\n    \n    if epoch % 2 == 0:\n        print(f\"epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}\")\n        \nprint(f\"Prediction after training: f(5) = {forward(5):.3f}\")\n","execution_count":8,"outputs":[{"output_type":"stream","text":"Prediction before training: f(5) = 0.000\nepoch 1: w = 1.200, loss = 30.00000000\nepoch 3: w = 1.872, loss = 0.76800019\nepoch 5: w = 1.980, loss = 0.01966083\nepoch 7: w = 1.997, loss = 0.00050331\nepoch 9: w = 1.999, loss = 0.00001288\nepoch 11: w = 2.000, loss = 0.00000033\nepoch 13: w = 2.000, loss = 0.00000001\nepoch 15: w = 2.000, loss = 0.00000000\nepoch 17: w = 2.000, loss = 0.00000000\nepoch 19: w = 2.000, loss = 0.00000000\nPrediction after training: f(5) = 10.000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title training pipeline\n\"\"\"\nprediction: manually\ngradient computation: autograd\nloss computation: manually\nparameter updates: manually\n\"\"\"\n\nimport torch\n\n\nX = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\nY = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n\nw = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n\n# model prediction\ndef forward(x):\n    return w * x\n\n# loss = MSE\ndef loss(y, y_predicted):\n    return((y_predicted - y)**2).mean()\n\nprint(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n\n# Training\nlearning_rate = 0.01\nn_iters = 100\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = forward(X)\n    \n    # loss\n    l = loss(Y, y_pred)\n    \n    # gradients = backward pass\n    l.backward() # dl/dw\n    \n    # update weight\n    with torch.no_grad():\n        w -= learning_rate * w.grad\n    \n    # zero gradients\n    w.grad.zero_()\n    \n    if epoch % 10 == 0:\n        print(f\"epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}\")\n        \nprint(f\"Prediction after training: f(5) = {forward(5):.3f}\")\n","execution_count":3,"outputs":[{"output_type":"stream","text":"Prediction before training: f(5) = 0.000\nepoch 1: w = 0.300, loss = 30.00000000\nepoch 11: w = 1.665, loss = 1.16278565\nepoch 21: w = 1.934, loss = 0.04506890\nepoch 31: w = 1.987, loss = 0.00174685\nepoch 41: w = 1.997, loss = 0.00006770\nepoch 51: w = 1.999, loss = 0.00000262\nepoch 61: w = 2.000, loss = 0.00000010\nepoch 71: w = 2.000, loss = 0.00000000\nepoch 81: w = 2.000, loss = 0.00000000\nepoch 91: w = 2.000, loss = 0.00000000\nPrediction after training: f(5) = 10.000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title linear regression\n\"\"\"\nprediction: pytorch model\ngradient computation: autograd\nloss computation: pytorch loss\nparameter updates: pytorch optimizer\n\"\"\"\n\n# 1. Design model(input, output size, forward pass)\n# 2. Construct loss and optimizer\n# 3. Training loop\n#    - forward pass: compute prediction and loss\n#    - backward pass: gradients\n#    - update weights\n\nimport torch\nimport torch.nn as nn\n\n\nX = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\nY = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n\nX_test = torch.tensor([5], dtype=torch.float32)\nn_samples, n_features = X.shape\nprint(f\"n_samples: {n_samples}\")\nprint(f\"n_features: {n_features}\")\nprint(\"\")\n\ninput_size = n_features\noutput_size = n_features\n\n# model = nn.Linear(input_size, output_size)\nclass LinearRegression(nn.Module):\n    \n    def __init__(self, input_dim, output_dim):\n        super(LinearRegression, self).__init__()\n        \n        # define layers\n        self.lin = nn.Linear(input_dim, output_dim)\n    \n    def forward(self, x):\n        return self.lin(x)\n\nmodel = LinearRegression(input_size, output_size)\n    \nprint(f\"Prediction before training: f(5) = {model(X_test).item():.3f}\")\n\n# Training\nlearning_rate = 0.01\nn_iters = 100\n\nloss = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nfor epoch in range(n_iters):\n    # prediction = forward pass\n    y_pred = model(X)\n    \n    # loss\n    l = loss(Y, y_pred)\n    \n    # gradients = backward pass\n    l.backward() # dl/dw\n    \n    # update weight\n    optimizer.step()\n    \n    # zero gradients\n    optimizer.zero_grad()\n    \n    if epoch % 10 == 0:\n        [w, b] = model.parameters()\n        print(f\"epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n        \nprint(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")","execution_count":19,"outputs":[{"output_type":"stream","text":"n_samplers: 4\nn_features: 1\n\nPrediction before training: f(5) = 0.752\nepoch 1: w = 0.252, loss = 22.89918518\nepoch 11: w = 1.355, loss = 0.86191410\nepoch 21: w = 1.543, loss = 0.27607319\nepoch 31: w = 1.583, loss = 0.24614540\nepoch 41: w = 1.600, loss = 0.23145974\nepoch 51: w = 1.612, loss = 0.21797828\nepoch 61: w = 1.624, loss = 0.20529068\nepoch 71: w = 1.635, loss = 0.19334158\nepoch 81: w = 1.646, loss = 0.18208808\nepoch 91: w = 1.656, loss = 0.17148960\nPrediction after training: f(5) = 9.311\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title linear regression\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn import datasets\nimport matplotlib.pyplot as plt\n\n\n# 0. Prepare data\nX_numpy, y_numpy = datasets.make_regression(n_samples=100, \n                                            n_features=1, noise=20,\n                                            random_state=1)\n\nX = torch.from_numpy(X_numpy.astype(np.float32))\ny = torch.from_numpy(y_numpy.astype(np.float32))\ny = y.view(y.shape[0], 1)\n\nn_samples, n_features = X.shape\n\n\n# 1. Design model(input, output size, forward pass)\ninput_size = n_features\noutput_size = 1\n\nmodel = nn.Linear(input_size, output_size)\n\n\n# 2. Construct loss and optimizer\nlearning_rate = 0.01\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\n# 3. Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n   \n    # forward pass: compute prediction & loss\n    y_predicted = model(X)\n    loss = criterion(y_predicted, y)\n    \n    # backward pass: gradients\n    loss.backward()\n    \n    # update weights\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    if (epoch + 1) % 10 == 0:\n        print(f\"epoch: {epoch}, loss: {loss.item():.4f}\")\n        \n# plot\npredicted = model(X).detach().numpy()\nplt.plot(X_numpy, y_numpy, \"ro\")\nplt.plot(X_numpy, predicted, \"b\")\nplt.show()","execution_count":13,"outputs":[{"output_type":"stream","text":"epoch: 9, loss: 4475.5918\nepoch: 19, loss: 3336.2056\nepoch: 29, loss: 2512.1689\nepoch: 39, loss: 1915.5463\nepoch: 49, loss: 1483.1375\nepoch: 59, loss: 1169.4478\nepoch: 69, loss: 941.6843\nepoch: 79, loss: 776.1774\nepoch: 89, loss: 655.8210\nepoch: 99, loss: 568.2388\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title logistic regression\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\n# 0. Prepare data\nbc = datasets.load_breast_cancer()\nX, y = bc.data, bc.target\n\nn_samples, n_features = X.shape\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.2,\n                                                    random_state=1234)\n# scale\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nX_train = torch.from_numpy(X_train.astype(np.float32))\nX_test = torch.from_numpy(X_test.astype(np.float32))\ny_train = torch.from_numpy(y_train.astype(np.float32))\ny_test = torch.from_numpy(y_test.astype(np.float32))\n\ny_train = y_train.view(y_train.shape[0], 1)\ny_test = y_test.view(y_test.shape[0], 1)\n\n\n# 1. Design model(input, output size, forward pass)\n# f = wx + b, sigmoid at the end\nclass LogisticRegression(nn.Module):\n    \n    def __init__(self, n_input_features):\n        super(LogisticRegression, self).__init__()\n        \n        # define layers \n        self.linear =  nn.Linear(n_input_features, 1)\n        \n    def forward(self, x):\n        y_predicted = torch.sigmoid(self.linear(x))\n        return y_predicted\n    \nmodel = LogisticRegression(n_features)\n\n\n# 2. Construct loss and optimizer\nlearning_rate =  0.01\ncriterion = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\n# 3. Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    # forward pass: compute prediction & loss\n    y_predicted = model(X_train)\n    loss = criterion(y_predicted, y_train)\n        \n    # backward pass: gradients\n    loss.backward()\n    \n    # update weights\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    if (epoch + 1) % 10 == 0:\n        print(f\"epoch {epoch}: loss = {loss.item():.4f}\")\n        \nwith torch.no_grad():\n    y_predicted = model(X_test)\n    y_predicted_cls = y_predicted.round()\n    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n    print(f\"accuracy = {acc:.4f}\")","execution_count":2,"outputs":[{"output_type":"stream","text":"epoch 9: loss = 0.5626\nepoch 19: loss = 0.4792\nepoch 29: loss = 0.4226\nepoch 39: loss = 0.3813\nepoch 49: loss = 0.3498\nepoch 59: loss = 0.3247\nepoch 69: loss = 0.3042\nepoch 79: loss = 0.2870\nepoch 89: loss = 0.2723\nepoch 99: loss = 0.2596\naccuracy = 0.9123\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"metadata":{"interpreter":{"hash":"00daf039bebfbba9c5a16e8bb486e8e5c71cf3417ae067aad70a9b390997a725"}}},"nbformat":4,"nbformat_minor":2}